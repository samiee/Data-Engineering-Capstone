{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd,re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "#### Scope\n",
    "\n",
    "\n",
    "In this project we will clean and aggregate data immigration Data and make our first diminsion table then we will try to make the second diminsion table Airports . The two datasets will be joined on airports code to form the fact table.\n",
    "The third diminsion contains informations about city demographics \n",
    "```\n",
    "i94mon  = numeric month\n",
    "i94cit  = 3 digit code of origin city\n",
    "i94port = 3 character code of destination USA city\n",
    "arrdate = arrival date in the USA\n",
    "i94mode = 1 digit travel code\n",
    "depdate = departure date from the USA\n",
    "i94visa = reason for immigration\n",
    "\n",
    "```\n",
    "The Seconed diminsion :\n",
    "```\n",
    "Airport Name = Airoprt name\n",
    "State_Code   = State CODE\n",
    "i94port      = 3 character code of destination USA city\n",
    "```\n",
    "The Third diminsion : \n",
    "```\n",
    "City              = City name                    \n",
    "State             = State                   \n",
    "Median Age        = Median age if the city               \n",
    "Male Population   = Male population        \n",
    "Total Population  = Total population        \n",
    "Foreign-born      = Number of foreign-born\n",
    "```\n",
    "#### Describe and Gather Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Wrangling Data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "path=\"./us-cities-demographics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo = spark.read.option(\"sep\", \";\").csv(path,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo_pd=pd.read_csv(path,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229.0</td>\n",
       "      <td>62432.0</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>7517.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712.0</td>\n",
       "      <td>41971.0</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815.0</td>\n",
       "      <td>8355.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629.0</td>\n",
       "      <td>56860.0</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>37038.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762.0</td>\n",
       "      <td>43270.0</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783.0</td>\n",
       "      <td>3269.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751.0</td>\n",
       "      <td>58077.0</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204.0</td>\n",
       "      <td>16315.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Folsom</td>\n",
       "      <td>California</td>\n",
       "      <td>40.9</td>\n",
       "      <td>41051.0</td>\n",
       "      <td>35317.0</td>\n",
       "      <td>76368</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13234.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>CA</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>5822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Folsom</td>\n",
       "      <td>California</td>\n",
       "      <td>40.9</td>\n",
       "      <td>41051.0</td>\n",
       "      <td>35317.0</td>\n",
       "      <td>76368</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13234.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>CA</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>34.1</td>\n",
       "      <td>741270.0</td>\n",
       "      <td>826172.0</td>\n",
       "      <td>1567442</td>\n",
       "      <td>61995.0</td>\n",
       "      <td>205339.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>PA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>122721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354.0</td>\n",
       "      <td>197601.0</td>\n",
       "      <td>389955</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>KS</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>65162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wichita</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>34.6</td>\n",
       "      <td>192354.0</td>\n",
       "      <td>197601.0</td>\n",
       "      <td>389955</td>\n",
       "      <td>23978.0</td>\n",
       "      <td>40270.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>KS</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>8791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.3</td>\n",
       "      <td>36850.0</td>\n",
       "      <td>37165.0</td>\n",
       "      <td>74015</td>\n",
       "      <td>4312.0</td>\n",
       "      <td>15365.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>50169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>32.9</td>\n",
       "      <td>149690.0</td>\n",
       "      <td>154695.0</td>\n",
       "      <td>304385</td>\n",
       "      <td>17728.0</td>\n",
       "      <td>28187.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>PA</td>\n",
       "      <td>White</td>\n",
       "      <td>208863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>28.8</td>\n",
       "      <td>124305.0</td>\n",
       "      <td>131484.0</td>\n",
       "      <td>255789</td>\n",
       "      <td>4921.0</td>\n",
       "      <td>68427.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>32.5</td>\n",
       "      <td>60142.0</td>\n",
       "      <td>60829.0</td>\n",
       "      <td>120971</td>\n",
       "      <td>3736.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>27089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>35.2</td>\n",
       "      <td>63278.0</td>\n",
       "      <td>62938.0</td>\n",
       "      <td>126216</td>\n",
       "      <td>4426.0</td>\n",
       "      <td>52281.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>55847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City           State  Median Age  Male Population  \\\n",
       "0      Silver Spring        Maryland        33.8          40601.0   \n",
       "1             Quincy   Massachusetts        41.0          44129.0   \n",
       "2             Hoover         Alabama        38.5          38040.0   \n",
       "3   Rancho Cucamonga      California        34.5          88127.0   \n",
       "4             Newark      New Jersey        34.6         138040.0   \n",
       "5             Peoria        Illinois        33.1          56229.0   \n",
       "6           Avondale         Arizona        29.1          38712.0   \n",
       "7        West Covina      California        39.8          51629.0   \n",
       "8           O'Fallon        Missouri        36.0          41762.0   \n",
       "9         High Point  North Carolina        35.5          51751.0   \n",
       "10            Folsom      California        40.9          41051.0   \n",
       "11            Folsom      California        40.9          41051.0   \n",
       "12      Philadelphia    Pennsylvania        34.1         741270.0   \n",
       "13           Wichita          Kansas        34.6         192354.0   \n",
       "14           Wichita          Kansas        34.6         192354.0   \n",
       "15        Fort Myers         Florida        37.3          36850.0   \n",
       "16        Pittsburgh    Pennsylvania        32.9         149690.0   \n",
       "17            Laredo           Texas        28.8         124305.0   \n",
       "18          Berkeley      California        32.5          60142.0   \n",
       "19       Santa Clara      California        35.2          63278.0   \n",
       "\n",
       "    Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0             41862.0             82463              1562.0       30908.0   \n",
       "1             49500.0             93629              4147.0       32935.0   \n",
       "2             46799.0             84839              4819.0        8229.0   \n",
       "3             87105.0            175232              5821.0       33878.0   \n",
       "4            143873.0            281913              5829.0       86253.0   \n",
       "5             62432.0            118661              6634.0        7517.0   \n",
       "6             41971.0             80683              4815.0        8355.0   \n",
       "7             56860.0            108489              3800.0       37038.0   \n",
       "8             43270.0             85032              5783.0        3269.0   \n",
       "9             58077.0            109828              5204.0       16315.0   \n",
       "10            35317.0             76368              4187.0       13234.0   \n",
       "11            35317.0             76368              4187.0       13234.0   \n",
       "12           826172.0           1567442             61995.0      205339.0   \n",
       "13           197601.0            389955             23978.0       40270.0   \n",
       "14           197601.0            389955             23978.0       40270.0   \n",
       "15            37165.0             74015              4312.0       15365.0   \n",
       "16           154695.0            304385             17728.0       28187.0   \n",
       "17           131484.0            255789              4921.0       68427.0   \n",
       "18            60829.0            120971              3736.0       25000.0   \n",
       "19            62938.0            126216              4426.0       52281.0   \n",
       "\n",
       "    Average Household Size State Code                               Race  \\\n",
       "0                     2.60         MD                 Hispanic or Latino   \n",
       "1                     2.39         MA                              White   \n",
       "2                     2.58         AL                              Asian   \n",
       "3                     3.18         CA          Black or African-American   \n",
       "4                     2.73         NJ                              White   \n",
       "5                     2.40         IL  American Indian and Alaska Native   \n",
       "6                     3.18         AZ          Black or African-American   \n",
       "7                     3.56         CA                              Asian   \n",
       "8                     2.77         MO                 Hispanic or Latino   \n",
       "9                     2.65         NC                              Asian   \n",
       "10                    2.62         CA                 Hispanic or Latino   \n",
       "11                    2.62         CA  American Indian and Alaska Native   \n",
       "12                    2.61         PA                              Asian   \n",
       "13                    2.56         KS                 Hispanic or Latino   \n",
       "14                    2.56         KS  American Indian and Alaska Native   \n",
       "15                    2.45         FL                              White   \n",
       "16                    2.13         PA                              White   \n",
       "17                    3.66         TX  American Indian and Alaska Native   \n",
       "18                    2.35         CA                              Asian   \n",
       "19                    2.75         CA                              White   \n",
       "\n",
       "     Count  \n",
       "0    25924  \n",
       "1    58723  \n",
       "2     4759  \n",
       "3    24437  \n",
       "4    76402  \n",
       "5     1343  \n",
       "6    11592  \n",
       "7    32716  \n",
       "8     2583  \n",
       "9    11060  \n",
       "10    5822  \n",
       "11     998  \n",
       "12  122721  \n",
       "13   65162  \n",
       "14    8791  \n",
       "15   50169  \n",
       "16  208863  \n",
       "17    1253  \n",
       "18   27089  \n",
       "19   55847  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_pd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Bay</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>37508.0</td>\n",
       "      <td>75485</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>13192.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>31672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>Bay</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>37508.0</td>\n",
       "      <td>75485</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>13192.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>Bay</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>37508.0</td>\n",
       "      <td>75485</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>13192.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>White</td>\n",
       "      <td>48797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>Bay</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>37508.0</td>\n",
       "      <td>75485</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>13192.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>16782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>Bay</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.9</td>\n",
       "      <td>37977.0</td>\n",
       "      <td>37508.0</td>\n",
       "      <td>75485</td>\n",
       "      <td>3478.0</td>\n",
       "      <td>13192.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     City  State  Median Age  Male Population  Female Population  \\\n",
       "1352  Bay  Texas        32.9          37977.0            37508.0   \n",
       "2106  Bay  Texas        32.9          37977.0            37508.0   \n",
       "2351  Bay  Texas        32.9          37977.0            37508.0   \n",
       "2554  Bay  Texas        32.9          37977.0            37508.0   \n",
       "2860  Bay  Texas        32.9          37977.0            37508.0   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "1352             75485              3478.0       13192.0   \n",
       "2106             75485              3478.0       13192.0   \n",
       "2351             75485              3478.0       13192.0   \n",
       "2554             75485              3478.0       13192.0   \n",
       "2860             75485              3478.0       13192.0   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "1352                    2.59         TX                 Hispanic or Latino   \n",
       "2106                    2.59         TX                              Asian   \n",
       "2351                    2.59         TX                              White   \n",
       "2554                    2.59         TX          Black or African-American   \n",
       "2860                    2.59         TX  American Indian and Alaska Native   \n",
       "\n",
       "      Count  \n",
       "1352  31672  \n",
       "2106   2819  \n",
       "2351  48797  \n",
       "2554  16782  \n",
       "2860   2167  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_pd[df_demo_pd[\"City\"]==\"Bay\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|summary|   City|    State|       Median Age|   Male Population| Female Population|  Total Population|Number of Veterans|      Foreign-born|Average Household Size|State Code|                Race|             Count|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|  count|   2891|     2891|             2891|              2888|              2888|              2891|              2878|              2878|                  2875|      2891|                2891|              2891|\n",
      "|   mean|   null|     null|35.49488066413016| 97328.42624653739|101769.63088642659|198966.77931511588| 9367.832522585128|40653.598679638635|     2.742542608695655|      null|                null| 48963.77447250087|\n",
      "| stddev|   null|     null|4.401616730099886|216299.93692873296|231564.57257148277| 447555.9296335903| 13211.21992386408| 155749.1036650984|    0.4332910878973046|      null|                null|144385.58856460615|\n",
      "|    min|Abilene|  Alabama|             22.9|            100135|            100260|            100247|             10001|             10024|                   2.0|        AK|American Indian a...|            100055|\n",
      "|    max|   Yuma|Wisconsin|             70.5|             99967|             99430|             99897|              9988|              9929|                  4.98|        WI|               White|             99948|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94_port=pd.read_csv('./i94_airport_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>i94port_clean</th>\n",
       "      <th>i94_airport_name_clean</th>\n",
       "      <th>i94_state_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 i94port_clean    i94_airport_name_clean   i94_state_clean\n",
       "0           0           ALC                     ALCAN   AK             \n",
       "1           1           ANC                 ANCHORAGE       AK         \n",
       "2           2           BAR  BAKER AAF - BAKER ISLAND                AK\n",
       "3           3           DAC             DALTONS CACHE           AK     \n",
       "4           4           PIZ    DEW STATION PT LAY DEW                AK"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94_port.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94_port.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "Valid_ports=list(df_i94_port.i94port_clean.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "valid_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in Valid_ports:\n",
    "    j = i.replace(' ','')\n",
    "    valid_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94_ports = spark.read.option(\"sep\", \",\").csv('i94_airport_codes.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------------+------------------+\n",
      "|_c0|i94port_clean|i94_airport_name_clean|   i94_state_clean|\n",
      "+---+-------------+----------------------+------------------+\n",
      "|  0|          ALC|                 ALCAN|   AK             |\n",
      "|  1|          ANC|             ANCHORAGE|       AK         |\n",
      "|  2|          BAR|  BAKER AAF - BAKER...|                AK|\n",
      "|  3|          DAC|         DALTONS CACHE|           AK     |\n",
      "|  4|          PIZ|  DEW STATION PT LA...|                AK|\n",
      "|  5|          DTH|          DUTCH HARBOR|          AK      |\n",
      "|  6|          EGL|                 EAGLE|   AK             |\n",
      "|  7|          FRB|             FAIRBANKS|       AK         |\n",
      "|  8|          HOM|                 HOMER|   AK             |\n",
      "|  9|          HYD|                 HYDER|   AK             |\n",
      "| 10|          JUN|                JUNEAU|    AK            |\n",
      "| 11|          5KE|             KETCHIKAN|                AK|\n",
      "| 12|          KET|             KETCHIKAN|       AK         |\n",
      "| 13|          MOS|  MOSES POINT INTER...|                AK|\n",
      "| 14|          NIK|               NIKISKI|     AK           |\n",
      "| 15|          NOM|                   NOM| AK               |\n",
      "| 16|          PKC|           POKER CREEK|         AK       |\n",
      "| 17|          ORI|        PORT LIONS SPB|                AK|\n",
      "| 18|          SKA|               SKAGWAY|     AK           |\n",
      "| 19|          SNP|       ST. PAUL ISLAND|                AK|\n",
      "+---+-------------+----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_ports.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- i94port_clean: string (nullable = true)\n",
      " |-- i94_airport_name_clean: string (nullable = true)\n",
      " |-- i94_state_clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_ports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_i94_ports=df_i94_ports.drop(df_i94_ports['_c0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+------------------+\n",
      "|i94port_clean|i94_airport_name_clean|   i94_state_clean|\n",
      "+-------------+----------------------+------------------+\n",
      "|          ALC|                 ALCAN|   AK             |\n",
      "|          ANC|             ANCHORAGE|       AK         |\n",
      "|          BAR|  BAKER AAF - BAKER...|                AK|\n",
      "|          DAC|         DALTONS CACHE|           AK     |\n",
      "|          PIZ|  DEW STATION PT LA...|                AK|\n",
      "|          DTH|          DUTCH HARBOR|          AK      |\n",
      "|          EGL|                 EAGLE|   AK             |\n",
      "|          FRB|             FAIRBANKS|       AK         |\n",
      "|          HOM|                 HOMER|   AK             |\n",
      "|          HYD|                 HYDER|   AK             |\n",
      "|          JUN|                JUNEAU|    AK            |\n",
      "|          5KE|             KETCHIKAN|                AK|\n",
      "|          KET|             KETCHIKAN|       AK         |\n",
      "|          MOS|  MOSES POINT INTER...|                AK|\n",
      "|          NIK|               NIKISKI|     AK           |\n",
      "|          NOM|                   NOM| AK               |\n",
      "|          PKC|           POKER CREEK|         AK       |\n",
      "|          ORI|        PORT LIONS SPB|                AK|\n",
      "|          SKA|               SKAGWAY|     AK           |\n",
      "|          SNP|       ST. PAUL ISLAND|                AK|\n",
      "+-------------+----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94_ports.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "valid_list_arr=np.array(valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_i94_data(immigration_file):\n",
    "    \n",
    "    '''\n",
    "    Input: Path to I94 immigration data file\n",
    "    \n",
    "    Output: Spark dataframe of I94 immigration data with valid i94port\n",
    "    \n",
    "    '''\n",
    "    spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "    .enableHiveSupport().getOrCreate()\n",
    "\n",
    "    # Read I94 data into Spark\n",
    "    spark_df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(immigration_file)\n",
    "#     vartype = df_immigration.schema\n",
    "#     df2 = spark.read.format('csv').option('header','True').option('delimiter','|').schema(vartype).load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.csv')\n",
    "\n",
    "    # Filter out entries where i94port is invalid\n",
    "    filtered=spark_df_immigration['i94port'].isin(valid_list_arr)\n",
    "\n",
    "    return spark_df_immigration[filtered].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "For the I94 immigration data, we want to drop all entries where the destination city code i94port is not a valid value (e.g., XXX, 99, etc) as described in I94_SAS_Labels_Description.SAS. we want to drop all entries where demographics is NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|summary|   City|    State|       Median Age|   Male Population| Female Population|  Total Population|Number of Veterans|      Foreign-born|Average Household Size|State Code|                Race|             Count|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "|  count|   2891|     2891|             2891|              2888|              2888|              2891|              2878|              2878|                  2875|      2891|                2891|              2891|\n",
      "|   mean|   null|     null|35.49488066413016| 97328.42624653739|101769.63088642659|198966.77931511588| 9367.832522585128|40653.598679638635|     2.742542608695655|      null|                null| 48963.77447250087|\n",
      "| stddev|   null|     null|4.401616730099886|216299.93692873296|231564.57257148277| 447555.9296335903| 13211.21992386408| 155749.1036650984|    0.4332910878973046|      null|                null|144385.58856460615|\n",
      "|    min|Abilene|  Alabama|             22.9|            100135|            100260|            100247|             10001|             10024|                   2.0|        AK|American Indian a...|            100055|\n",
      "|    max|   Yuma|Wisconsin|             70.5|             99967|             99430|             99897|              9988|              9929|                  4.98|        WI|               White|             99948|\n",
      "+-------+-------+---------+-----------------+------------------+------------------+------------------+------------------+------------------+----------------------+----------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo.describe().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       0\n",
       "State                      0\n",
       "Median Age                 0\n",
       "Male Population            3\n",
       "Female Population          3\n",
       "Total Population           0\n",
       "Number of Veterans        13\n",
       "Foreign-born              13\n",
       "Average Household Size    16\n",
       "State Code                 0\n",
       "Race                       0\n",
       "Count                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_pd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_demo=df_demo.filter(df_demo['Male Population'] != 'NaN')\n",
    "df_demo=df_demo.filter(df_demo['Female Population'] != 'NaN')\n",
    "df_demo=df_demo.filter(df_demo['Foreign-born'] != 'NaN')\n",
    "df_demo=df_demo.filter(df_demo['Total Population'] != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_data = '/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "df_immigration = clean_i94_data(immigration_data)\n",
    "\n",
    "# Extract columns for immigration dimension table\n",
    "immigration_table = df_immigration.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\",\"arrdate\"])\n",
    "\n",
    "# Write immigration dimension table to parquet files partitioned by i94port\n",
    "immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Extract columns for US Demographics dimension table\n",
    "demog_table=df_demo.select(F.col(\"City\").alias(\"City\"),\n",
    "  F.col(\"State\").alias(\"State\"),\n",
    "  F.col(\"Median Age\").alias(\"Median_Age\"),\n",
    "  F.col(\"Male Population\").alias(\"Male_Population\"),\n",
    "  F.col(\"State Code\").alias(\"State_Code\"),\n",
    "  F.col(\"Female Population\").alias(\"Female_Population\"),\n",
    "  F.col(\"Total Population\").alias(\"Total_Population\"),\n",
    "  F.col (\"Foreign-born\").alias(\"Foreign_born\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+----------+-----------------+----------------+------------+\n",
      "|            City|        State|Median_Age|Male_Population|State_Code|Female_Population|Total_Population|Foreign_born|\n",
      "+----------------+-------------+----------+---------------+----------+-----------------+----------------+------------+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|        MD|            41862|           82463|       30908|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|        MA|            49500|           93629|       32935|\n",
      "|          Hoover|      Alabama|      38.5|          38040|        AL|            46799|           84839|        8229|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|        CA|            87105|          175232|       33878|\n",
      "|          Newark|   New Jersey|      34.6|         138040|        NJ|           143873|          281913|       86253|\n",
      "+----------------+-------------+----------+---------------+----------+-----------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demog_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write Demographics dimension table to parquet files partitioned by City\n",
    "demog_table.write.mode(\"append\").partitionBy(\"State_Code\").parquet(\"./results/demographics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_table=df_i94_ports.select(F.col(\"i94port_clean\").alias(\"i94port\"),\n",
    "  F.col(\"i94_airport_name_clean\").alias(\"i94_airport_name\"),\n",
    "  F.col(\"i94_state_clean\").alias(\"i94_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"./results/airports.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immigration.createOrReplaceTempView(\"immigration_view\")\n",
    "df_i94_ports.createOrReplaceTempView(\"air_ports_view\")\n",
    "\n",
    "# Create the fact table by joining the immigration and temperature views\n",
    "fact_table = spark.sql('''\n",
    "SELECT immigration_view.i94yr as year,\n",
    "       immigration_view.i94mon as month,\n",
    "       immigration_view.i94cit as city,\n",
    "       immigration_view.i94port as i94port,\n",
    "       immigration_view.arrdate as arrival_date,\n",
    "       immigration_view.depdate as departure_date,\n",
    "       immigration_view.i94visa as reason,\n",
    "       air_ports_view.i94_airport_name_clean as Airport_name,\n",
    "       air_ports_view.i94_state_clean as State Code,\n",
    "       air_ports_view.i94port_clean i94port\n",
    "FROM immigration_view\n",
    "JOIN air_ports_view ON (immigration_view.i94port = air_ports_view.i94port)\n",
    "''')\n",
    "# Write fact table to parquet files partitioned by i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The first dimension contains events from the I94 immigration data. The columns below will be extracted from the immigration dataframe:\n",
    "```\n",
    "* i94yr = 4 digit year\n",
    "* i94mon = numeric month\n",
    "* i94cit = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "* arrdate = arrival date\n",
    "* i94mode = 1 digit travel code\n",
    "* depdate = departure date\n",
    "* i94visa = reason for immigration\n",
    "```\n",
    "The seconed dimension will contains the columns of airports code  names and state code:\n",
    "```\n",
    "* Airport_name= Airport name\n",
    "* State Code = 3 digit code of origin city\n",
    "* i94port = 3 character code of destination city\n",
    "```\n",
    "The Third dimension will contains the columns of us-demographics code  names and state code:\n",
    "```\n",
    "* City =City name \n",
    "* State=State Code\n",
    "* Median_Age= Median age of the city\n",
    "* Male_Population = Male Population count\n",
    "* State_Code = State Code\n",
    "* Female_Population = Female population count\n",
    "* Total_Population = total population count\n",
    "* Foreign_born = number of foreign born\n",
    "```\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1- Clean I94 data as described in step 2 to create Spark dataframe df_immigration for each month\n",
    "2- Clean demographics data as described in step 2 to create Spark dataframe df_demog\n",
    "3- Create immigration dimension table by selecting relevant columns from df_immigration and write to parquet file partitioned by i94port\n",
    "Create demographics dimension table by selecting relevant columns\n",
    "Create fact table by joining immigration and demographics dimension tables on i94port and write to parquet file partitioned by i94port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    \n",
    "    Output: Print outcome of data quality check\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    result = df.count()\n",
    "    if result == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(description, result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(df_immigration, \"immigration table\")\n",
    "quality_check(df_i94_ports, \"temperature table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "> Spark wawe could use a scheduling tool such as Airflow to run the ETL pipeline overnight.s chosen since and it can handle multiple file format  (including SAS) containing large amounts of data.Spark SQL used to manipulat large amount of data and doing join operation for tables.\n",
    "* Propose how often the data should be updated and why.\n",
    "> The data should be updated monthly \n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " > We couldn't deal with the data a single batch to perfome our analysis as I've tried to use the Race column on the fact table and I ran out of memory , and sure we are working in standalone mode but we could use Spark Cluster mode.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " > we could use a scheduling tool such as Airflow to run the ETL pipeline overnight.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " > If the database needed to be accessed by 100+ people, we could consider publishing the parquet files to HDFS and giving read access to users that need it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
